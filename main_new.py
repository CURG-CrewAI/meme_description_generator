# main.py
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import SerperDevTool, ScrapeWebsiteTool
from typing import Dict, Any
import json
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def _get_api_key():
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("Set GEMINI_API_KEY or GOOGLE_API_KEY in your .env")
    return api_key

def _check_serper_key():
    if not os.getenv("SERPER_API_KEY"):
        raise RuntimeError("Set SERPER_API_KEY in your .env (required by SerperDevTool)")

class MemeAgentCrew:
    def __init__(self):
        # ë„êµ¬ ì„¤ì •
        _check_serper_key()
        self.search_tool = SerperDevTool()
        self.scrape_tool = ScrapeWebsiteTool()

        # CrewAIì˜ LLMìœ¼ë¡œ provider+modelì„ ëª…ì‹œ
        api_key = _get_api_key()
        self.gemini_pro = LLM(api_key=api_key, model="gemini/gemini-2.5-pro")
        self.gemini_flash = LLM(api_key=api_key, model="gemini/gemini-2.5-flash")
        self.gemini_flash_lite = LLM(api_key=api_key, model="gemini/gemini-2.5-flash-lite")
     
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ê¸°ì‚¬ URL ìˆ˜ì§‘ ì—ì´ì „íŠ¸
        self.search_agent = Agent(
            role='í•œêµ­ ë‰´ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€',
            goal='ì£¼ì–´ì§„ í‚¤ì›Œë“œì˜ ìµœì‹  í•œêµ­ ë‰´ìŠ¤ ê¸°ì‚¬ URLê³¼ ì œëª©ì„ ìˆ˜ì§‘',
            backstory=(
                """ë‹¹ì‹ ì€ í•œêµ­ì˜ ì‹¤ì‹œê°„ ì´ìŠˆì™€ ë‰´ìŠ¤ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°€ì§„ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì£¼ì–´ì§„ í‚¤ì›Œë“œë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í•œêµ­ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ì„ë¬´ì…ë‹ˆë‹¤.
                ë„¤ì´ë²„ ë‰´ìŠ¤, ë‹¤ìŒ ë‰´ìŠ¤, ì—°í•©ë‰´ìŠ¤, ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´ ë“± ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ ê¸°ì‚¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
                ê²€ìƒ‰í•  ë•ŒëŠ” site:naver.com ë˜ëŠ” site:daum.net ê°™ì€ ì‚¬ì´íŠ¸ ì§€ì • ê²€ìƒ‰ì„ í™œìš©í•©ë‹ˆë‹¤."""
            ),
            tools=[self.search_tool],
            verbose=True,
            llm=self.gemini_flash_lite
        )
       
        # ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ëŠ” ì—ì´ì „íŠ¸
        self.extractor_agent = Agent(
            role='ë‰´ìŠ¤ ë³¸ë¬¸ ì¶”ì¶œ ì „ë¬¸ê°€',
            goal='ê¸°ì‚¬ URLì—ì„œ í•µì‹¬ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ê³  ìš”ì•½',
            backstory=(
                """ë‹¹ì‹ ì€ ì›¹í˜ì´ì§€ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©, ë³¸ë¬¸, í•µì‹¬ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ 
                ë‹¤ìŒ ë‹¨ê³„ì˜ í’ìê¸€ ì‘ì„±ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
                ê´‘ê³ ë‚˜ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ì œì™¸í•˜ê³  ìˆœìˆ˜ ê¸°ì‚¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
                íŠ¹íˆ í•œêµ­ì–´ ê¸°ì‚¬ì—ì„œ ì¤‘ìš”í•œ ì‚¬ì‹¤ê³¼ ë°°ê²½ì„ íŒŒì•…í•˜ëŠ” ë° ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."""
            ),
            tools=[self.scrape_tool],
            verbose=True,
            llm=self.gemini_flash
        )
    
        # ì´ìŠˆì— ëŒ€í•œ í’ìê¸€ì„ ì‘ì„±í•˜ëŠ” ì—ì´ì „íŠ¸
        self.writer_agent = Agent(
            role='ë°ˆì½”ì¸ í’ìê¸€ ì‘ì„± ì „ë¬¸ê°€',
            goal='ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬ë¯¸ìˆê³  ì°½ì˜ì ì¸ ì˜ì–´ ë°ˆì½”ì¸ í’ìê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.',
            backstory="""
            ë‹¹ì‹ ì€ í•œêµ­ì˜ ì¸í„°ë„· ë¬¸í™”ì™€ ë°ˆì— ì •í†µí•œ ì°½ì˜ì ì¸ ì‘ê°€ì´ë©´ì„œ, 
            ê¸€ë¡œë²Œ ì•”í˜¸í™”í ë° ë°ˆì½”ì¸ íŠ¸ë Œë“œì—ë„ í•´ë°•í•œ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
            í•œêµ­ ì‹œì‚¬ ì´ìŠˆë¥¼ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ í’€ì–´ë‚´ë©°, ë°ˆì½”ì¸ì´ë¼ëŠ” ê°œë…ì— ë§ì¶° 
            ì¬ë¯¸ìˆìœ¼ë©´ì„œë„ ì ì ˆí•œ ì„ ì„ ì§€í‚¤ëŠ” ì˜ì–´ í’ìê¸€ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            
            ì‘ì„± ìŠ¤íƒ€ì¼:
            - í•œêµ­ ì´ìŠˆë¥¼ ê¸€ë¡œë²Œ ê´€ê°ì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ì˜ì–´ë¡œ ì„¤ëª…
            - ë°ˆì½”ì¸ì˜ íŠ¹ì„±ì„ ì‚´ë¦° ì°½ì˜ì ì¸ ë„¤ì´ë°ê³¼ ì»¨ì…‰
            - ì ì ˆí•œ ì´ëª¨ì§€ì™€ í•´ì‹œíƒœê·¸ í™œìš©
            - ê³¼ë„í•˜ì§€ ì•Šì€ ê±´ì „í•œ ìœ ë¨¸
            - íˆ¬ì ì£¼ì˜ì‚¬í•­ì„ ë°˜ë“œì‹œ í¬í•¨
        
            âš ï¸ ì¤‘ìš”: ëª¨ë“  ê²°ê³¼ë¬¼ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            """,
            verbose=True,
            llm=self.gemini_pro
        )

        # í† í¬ë…¸ë¯¹ìŠ¤ì™€ ë¡œë“œë§µì„ ì‘ì„±í•˜ëŠ” ì—ì´ì „íŠ¸
        self.tokenomics_agent = Agent(
            role='ë°ˆì½”ì¸ í† í¬ë…¸ë¯¹ìŠ¤ & ë¡œë“œë§µ ì„¤ê³„ì',
            goal='í’ìê¸€ì„ ë°”íƒ•ìœ¼ë¡œ í™©ë‹¹í•˜ê³  ì¬ë¯¸ìˆëŠ” í† í¬ë…¸ë¯¹ìŠ¤ì™€ ë¡œë“œë§µì„ ìƒì„±',
            backstory="""
            ë‹¹ì‹ ì€ ì–´ì´ì—†ì–´ì„œ í—›ì›ƒìŒì´ ë‚˜ì˜¤ëŠ” ë°ˆì½”ì¸ í”„ë¡œì íŠ¸ë¥¼ ì˜ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ì‹¤ì œ í¬ë¦½í†  í”„ë¡œì íŠ¸ì²˜ëŸ¼ ê·¸ëŸ´ë“¯í•œ í† í¬ë…¸ë¯¹ìŠ¤ì™€ 
            ì‹¤í˜„ ë¶ˆê°€ëŠ¥í•œ ë¡œë“œë§µì„ ë§Œë“¤ì–´ í’ìì™€ ìœ ë¨¸ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
        
            ì‘ì„± ìŠ¤íƒ€ì¼:
            - ì‹¤ì œ ë°±ì„œì²˜ëŸ¼ ì „ë¬¸ ìš©ì–´ ì‚¬ìš©í•˜ë˜ ë§ë„ ì•ˆ ë˜ëŠ” ë‚´ìš©
            - íŒŒì´ ì°¨íŠ¸, í¼ì„¼íŠ¸ ë“± ìˆ«ìë¥¼ í™œìš©í•œ ê°€ì§œ ë°ì´í„°
            - Q1, Q2 ê°™ì€ ë¶„ê¸°ë³„ ë¡œë“œë§µ (ë¶ˆê°€ëŠ¥í•œ ëª©í‘œë“¤)
            - ì§„ì§€í•œ í†¤ìœ¼ë¡œ ì›ƒê¸´ ë‚´ìš© ì „ë‹¬
        
            âš ï¸ ì¤‘ìš”: ëª¨ë“  ê²°ê³¼ë¬¼ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            """,
            verbose=True,
            llm=self.gemini_pro  
        )

        # ì›¹ì‚¬ì´íŠ¸ ë´‡ ì „ë‹¬ìš© JSON ë³€í™˜ ì—ì´ì „íŠ¸
        self.summary_agent = Agent(
            role='ì›¹ì‚¬ì´íŠ¸ ë´‡ ì—°ë™ìš© JSON ë³€í™˜ ì „ë¬¸ê°€',
            goal='í’ìê¸€ê³¼ í† í¬ë…¸ë¯¹ìŠ¤ë¥¼ ì›¹ì‚¬ì´íŠ¸ ë´‡ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜',
            backstory="""
            ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë°ˆì½”ì¸ í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬í•˜ëŠ” ê²ƒì´ ì„ë¬´ì…ë‹ˆë‹¤.
            ê° ì„¹ì…˜ì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ê³ , ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì‰½ê²Œ íŒŒì‹±í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.
            """,
            verbose=True,
            llm=self.gemini_flash
        )

    def create_search_task(self, keyword: str, why_trending: str):
        context_term = (why_trending or "").split(".")[0]
        return Task(
            description=f"""
            ì£¼ì–´ì§„ í‚¤ì›Œë“œ '{keyword}'ì™€ íŠ¸ë Œë”© ì´ìœ  '{why_trending}'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê°€ì¥ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ìµœì‹  í•œêµ­ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.

            ë‹¨ìˆœíˆ í‚¤ì›Œë“œë¡œë§Œ ê²€ìƒ‰í•˜ëŠ” ëŒ€ì‹ , ì•„ë˜ì˜ ê²€ìƒ‰ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì˜ ì§ˆì„ ë†’ì´ì„¸ìš”.

            1.  **íŠ¹ì • ë‰´ìŠ¤ í¬í„¸ íƒ€ê²Ÿ ê²€ìƒ‰:** `"{keyword}" site:news.naver.com` ë˜ëŠ” `"{keyword}" site:v.daum.net` ì™€ ê°™ì´ ì‹ ë¢°ë„ ë†’ì€ ì£¼ìš” í¬í„¸ì„ ì§ì ‘ ê²¨ëƒ¥í•˜ì—¬ ê²€ìƒ‰í•©ë‹ˆë‹¤.
            2.  **ì»¨í…ìŠ¤íŠ¸ í™œìš© ê²€ìƒ‰:** íŠ¸ë Œë”© ì´ìœ ì—ì„œ í•µì‹¬ ë‹¨ì–´ë¥¼ ë½‘ì•„ ê²€ìƒ‰ì–´ì— ì¡°í•©í•©ë‹ˆë‹¤. ì˜ˆ: `"{keyword}" {context_term}`
            3.  **ìµœì‹  í‚¤ì›Œë“œ ê²€ìƒ‰:** `"{keyword}" ìµœì‹  ë‰´ìŠ¤` ë˜ëŠ” `"{keyword}" ê³µì‹ì…ì¥` ê³¼ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ê°€ì¥ ìµœê·¼ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

            ì´ ì „ëµë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìµœì‹  ê¸°ì‚¬ 3~5ê°œë¥¼ ì°¾ì•„ ì œëª©, URL, ê°„ë‹¨í•œ ìš”ì•½ì„ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.

            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤:
            {{
            "keyword": "{keyword}",
            "articles": [
                {{
                    "title": "ê¸°ì‚¬ ì œëª©",
                    "url": "ê¸°ì‚¬ URL",
                    "snippet": "ê¸°ì‚¬ ìš”ì•½",
                    "source": "ì–¸ë¡ ì‚¬ëª…"
                }}
            ]
        }}
        """,
        expected_output="ì‹ ë¢°ë„ ë†’ì€ ìµœì‹  ê¸°ì‚¬ 5~7ê°œì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê¸´ JSON í˜•ì‹ì˜ ë¬¸ìì—´",
        agent=self.search_agent
    )
    
    def create_extraction_task(self):
        return Task(
            description="""
            ì´ì „ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ URLë“¤ì—ì„œ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”.
            
            ì¶”ì¶œ ìš”êµ¬ì‚¬í•­:
            1. ê° URLì— ì ‘ì†í•˜ì—¬ ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ
            2. ì œëª©, ì²« 2-3ë‹¨ë½ì˜ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì¶œ
            3. ê´‘ê³ , ê´€ë ¨ê¸°ì‚¬, ëŒ“ê¸€ ë“±ì€ ì œì™¸
            4. í•µì‹¬ ì‚¬ì‹¤ê³¼ ë§¥ë½ ì •ë³´ë§Œ ì •ë¦¬
            5. ì´ìŠˆì˜ ë°°ê²½ê³¼ í˜„ì¬ ìƒí™©ì„ ëª…í™•íˆ íŒŒì•…
            
            ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
            {{
                "extracted_content": [
                    {{
                        "title": "ê¸°ì‚¬ ì œëª©",
                        "content": "ì¶”ì¶œëœ í•µì‹¬ ë³¸ë¬¸",
                        "key_points": ["í•µì‹¬1", "í•µì‹¬2", "í•µì‹¬3"],
                        "background": "ì´ìŠˆ ë°°ê²½"
                    }}
                ]
            }}
            """,
            expected_output="JSON í˜•ì‹ì˜ ì¶”ì¶œëœ ê¸°ì‚¬ ë³¸ë¬¸ë“¤",
            agent=self.extractor_agent
        )
    
    def create_satire_task(self, keyword: str):
        return Task(
            description=f"""
            í‚¤ì›Œë“œ '{keyword}'ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ì–´ ë°ˆì½”ì¸ í’ìê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
            
            í’ìê¸€ ìš”êµ¬ì‚¬í•­:
            1. ì œëª©: ì°½ì˜ì ì¸ ë°ˆì½”ì¸ ì´ë¦„ê³¼ í‹°ì»¤ ex)Sonnywood, $SONNY
            2. ë³¸ë¬¸: ì´ìŠˆì— ëŒ€í•œ ì¬ë¯¸ìˆëŠ” ì˜ì–´ ì„¤ëª… (100-250 ë‹¨ì–´)
            3. íŠ¹ì§•: í•´ë‹¹ ë°ˆì½”ì¸ì˜ ìœ ë¨¸ëŸ¬ìŠ¤í•œ íŠ¹ì§• 1-4ê°œ (ì˜ì–´)
            4. ì£¼ì˜ì‚¬í•­: í’ìì— ê°€ê¹Œìš´ íˆ¬ì ì£¼ì˜ì‚¬í•­ ë° ë©´ì±…ì¡°í•­ (ì˜ì–´)
            5. í•´ì‹œíƒœê·¸: ê´€ë ¨ ì˜ì–´ í•´ì‹œíƒœê·¸ 5-7ê°œ
            
            í†¤ì•¤ë§¤ë„ˆ:
            - ìœ ë¨¸ëŸ¬ìŠ¤í•˜ì§€ë§Œ í’ˆê²©ìˆê²Œ
            - ê¸€ë¡œë²Œ ê´€ê°ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì˜ì–´ í‘œí˜„
            - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
            - ì•„ì´ëŸ¬ë‹ˆì™€ í’ìë¥¼ ì„ì–´ ì¬êµ¬ì„±í•˜ì„¸ìš”. ê³¼ì¥ë²•, ë¹„ìœ , ë§ì¥ë‚œ ë“±ì„ í™œìš©í•˜ì„¸ìš”.
            - í•œêµ­ ë¬¸í™”ì  ë§¥ë½ì„ ì˜ì–´ë¡œ ì˜ ì„¤ëª…
            - ìƒì†Œí•œ í•œêµ­ì˜ ì´ìŠˆë¥¼ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì „ë‹¬í•´ì•¼ í•¨
            âš ï¸ ì¤‘ìš”: ëª¨ë“  ë‚´ìš©ì„ ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            
            ì‘ì„± í˜•ì‹:
            ğŸš€ [COIN_NAME] Emergency Launch! 
            
            "[English Catchphrase]"
            
            [Korean issue explained in English with humor]
            
            âœ¨ Features:
            - Feature 1 in English
            - Feature 2 in English
            - Feature 3 in English
            
            âš ï¸ Investment Warning: 
            [Disclaimer in English about this being entertainment only]
            
            #hashtag1 #hashtag2 #hashtag3 #hashtag4 #hashtag5


            ì‘ì„± ê°€ì´ë“œ(Few Shot):
            ì•„ë˜ëŠ” 'ë°°ìš°ì˜ ì‚¬ìƒí™œ í™•ì¸ ë¶ˆê°€'ë¼ëŠ” ì£¼ì œë¡œ ì‘ì„±ëœ ì„±ê³µì ì¸ í’ìê¸€ì˜ ì‘ì„± ì˜ˆì‹œì…ë‹ˆë‹¤. 
            ì´ ì˜ˆì‹œì˜ ì°½ì˜ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í•™ìŠµí•˜ì—¬ ë‹¹ì‹ ì˜ ê²°ê³¼ë¬¼ì— ì ìš©í•˜ì„¸ìš”.

            ì£¼ì œ:ë°°ìš° ì •ìš°ì„±ì˜ 'ì‚¬ìƒí™œì´ë¼ í™•ì¸ ë¶ˆê°€'ë¼ëŠ” ê³µì‹ ì…ì¥
            í›Œë¥­í•œ Features ì‘ì„± ì˜ˆì‹œ:
            âœ¨ Features:
            - Non-Denial-Denial Protocol: Transactions are never officially confirmed, they just appear on the blockchain. We respect their privacy.
            - Plot Twist Burn Mechanism: A small percentage of the total supply is automatically burned every time a shocking new personal detail about a major public figure is "unable to be confirmed."
            - Stealth Wedding Rewards: Holders are airdropped bonus tokens when a long-term bachelor/bachelorette finallyâ€”and quietlyâ€”gets married without a press release.

            í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸: ìœ„ ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ì§€ëŠ” ë§ˆì‹­ì‹œì˜¤.
            ëŒ€ì‹ , í’ìì˜ í•µì‹¬ ì»¨ì…‰ì„ **'Protocol', 'Mechanism', 'Rewards', 'Tokenomics', 'Governance' ë“± ê·¸ëŸ´ë“¯í•œ ë¸”ë¡ì²´ì¸ ê´€ë ¨ ê¸°ìˆ  ìš©ì–´ë¡œ ì¬ì¹˜ìˆê²Œ í¬ì¥**í•˜ì—¬ ìœ ë¨¸ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤. ì£¼ì œì— ê°€ì¥ ì˜ ë§ëŠ” ìš©ì–´ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.
            ì˜ˆë¥¼ ë“¤ì–´, ì •ì¹˜ì¸ì„ í’ìí•  ë•ŒëŠ” Governance Modelì´ë‚˜ Voting Systemì´ ë” ì–´ìš¸ë¦´ ìˆ˜ ìˆê³ , ì‹í’ˆ ê´€ë ¨ ì´ìŠˆì—ëŠ” Supply Chain Tokenomicsê°€ ë”ìš± ì¬ë¯¸ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            ì¢‹ì€ Investment Warning ì‘ì„± ì˜ˆì‹œ:
            âš ï¸ A Note From Our Legal Team (Probably):
            Look, this is an emotional support token, not a financial instrument. Our entire whitepaper is a rumor someone started in a group chat. The liquidity pool is filled with pure, unadulterated speculation. Any resemblance to actual persons, living or dead, or actual events is purely coincidental and, frankly, a matter of their private life we cannot confirm. Buying this token will not make you rich, but it might make you laugh while you lose money on other, more serious-looking coins. This is not financial advice. This is performance art. DYOR (Do Your Own Research... on everything).

            í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸: ìœ„ ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ì§€ëŠ” ë§ˆì‹­ì‹œì˜¤.
            ë‹¤ë§Œ ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ê²½ê³ ë¬¸ ì „ì²´ë¥¼ ë§ˆì¹˜ ë°ˆì½”ì¸ ê°œë°œìì¸ ê²ƒì²˜ëŸ¼ ì‘ì„±í•˜ì—¬, ê²½ê³ í•˜ëŠ” ì²™í•˜ë©´ì„œ ì¬ë¯¸ìˆëŠ” í’ìë¥¼ ì´ì–´ë‚˜ê°€ëŠ” ì „ëµì€ ê¶Œì¥í•©ë‹ˆë‹¤.

            """,
            expected_output="ì™„ì„±ëœ ì˜ì–´ ë°ˆì½”ì¸ í’ìê¸€",
            agent=self.writer_agent
        )

    def create_tokenomics_task(self, keyword: str):
        return Task(
            description=f"""
            ì´ì „ ë‹¨ê³„(context)ì—ì„œ ìƒì„±ëœ '{keyword}' ë°ˆì½”ì¸ í’ìê¸€ì„ ë°”íƒ•ìœ¼ë¡œ í† í¬ë…¸ë¯¹ìŠ¤ì™€ ë¡œë“œë§µì„ ì‘ì„±í•˜ì„¸ìš”.

            ë‹¹ì‹ ì˜ ê°€ì¥ ì¤‘ìš”í•œ ì„ë¬´ëŠ” **ê¸€ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.
            í’ìê¸€ ë„ì…ë¶€ì— ì œì‹œëœ `âœ¨ Features` í•­ëª©ë“¤ì„, ë‹¹ì‹ ì´ ì‘ì„±í•  `TOKENOMICS`ì˜ `Special Features` ì„¹ì…˜ì—ì„œ **ë°˜ë“œì‹œ ê°€ì ¸ì™€ì„œ ìƒì„¸íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.** ì ˆëŒ€ ê·¸ ì•„ì´ë””ì–´ë“¤ì„ ë¬´ì‹œí•˜ê³  ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.

            ğŸ’¡ **ì›Œí¬í”Œë¡œìš° ê°€ì´ë“œ (Your Workflow):**
            1.  ì»¨í…ìŠ¤íŠ¸ë¡œ ë°›ì€ í’ìê¸€ì—ì„œ `âœ¨ Features` ì„¹ì…˜ì„ ì£¼ì˜ ê¹Šê²Œ ì½ìœ¼ì„¸ìš”.
            2.  ë‹¹ì‹ ì´ ì‘ì„±í•  `TOKENOMICS`ì˜ `Special Features` ì„¹ì…˜ ì œëª©ìœ¼ë¡œ, í•´ë‹¹ ê¸°ëŠ¥ë“¤ì˜ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
            3.  ê° ê¸°ëŠ¥ì´ í† í¬ë…¸ë¯¹ìŠ¤ ê´€ì ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€(ì˜ˆ: ìŠ¤í…Œì´í‚¹ ë°©ì‹, ì†Œê° ë°©ì‹, ë³´ìƒ ë°©ì‹ ë“±)ë¥¼ ì°½ì˜ì ì´ê³  ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•˜ì„¸ìš”.
            4.  ë§Œì•½ í’ìê¸€ì— ì—†ë˜ ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜(ì˜ˆ: ì¼ë°˜ ì†Œê°)ì„ ì¶”ê°€í•˜ê³  ì‹¶ë‹¤ë©´, ê¸°ì¡´ ê¸°ëŠ¥ë“¤ì„ ëª¨ë‘ ì„¤ëª…í•œ **í›„ì—** ë§ë¶™ì´ëŠ” ê²ƒì€ ê´œì°®ìŠµë‹ˆë‹¤.
        
            ğŸ“Š TOKENOMICS ìš”êµ¬ì‚¬í•­:
            1. Total Supply: í™©ë‹¹í•œ ìˆ«ì (ì˜ˆ: 420.69 trillion)
            2. Distribution:
            - Team: X% (ì›ƒê¸´ ì´ìœ ì™€ í•¨ê»˜)
            - Marketing: X% (í™©ë‹¹í•œ ë§ˆì¼€íŒ… ê³„íš)
            - Liquidity: X% 
            - Community: X% (ë§ë„ ì•ˆ ë˜ëŠ” ì»¤ë®¤ë‹ˆí‹° í˜œíƒ)
            3. Special Features:
            **(í•„ìˆ˜) í’ìê¸€ì˜ `âœ¨ Features`ì—ì„œ ê°€ì ¸ì˜¨ ì•„ì´ë””ì–´ë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…**
        
            ğŸ—ºï¸ ROADMAP ìš”êµ¬ì‚¬í•­:
            Q1 2025: [ê±°ì§“ë§ ê°™ì§€ë§Œ ì•½ê°„ í˜„ì‹¤ì„± ìˆëŠ” ëª©í‘œ]
            Q2 2025: [ê±°ì˜ ë¶ˆê°€ëŠ¥í•´ë³´ì´ëŠ” í™©ë‹¹í•œ ëª©í‘œ]
            Q3 2025: [ë¬¼ë¦¬ë²•ì¹™ ìœ„ë°˜ ìˆ˜ì¤€ì˜ ì™„ì „íˆ ë¶ˆê°€ëŠ¥í•œ ëª©í‘œ]
            Q4 2025: [ìš°ì£¼ ì •ë³µÂ·ì‹œê°„ì—¬í–‰ ìˆ˜ì¤€ì˜ ëª©í‘œ]
        
            í˜•ì‹:
            ğŸ“Š TOKENOMICS
            ================
            Total Supply: [ìˆ«ì]
        
            Distribution:
            â€¢ Team: X% - [ì›ƒê¸´ ì„¤ëª…]
            â€¢ Marketing: X% - [í™©ë‹¹í•œ ê³„íš]
            â€¢ Liquidity: X% - [ê³¼ì¥ëœ ì„¤ëª…]
            â€¢ Community: X% - [ë§ë„ ì•ˆ ë˜ëŠ” í˜œíƒ]
        
            Special Features:
            â€¢ [í’ìê¸€ì˜ `âœ¨ Features`ì—ì„œ ê°€ì ¸ì˜¨ ì•„ì´ë””ì–´ë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]
            â€¢ [í’ìê¸€ì˜ `âœ¨ Features`ì—ì„œ ê°€ì ¸ì˜¨ ì•„ì´ë””ì–´ë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]
            â€¢ [í’ìê¸€ì˜ `âœ¨ Features`ì—ì„œ ê°€ì ¸ì˜¨ ì•„ì´ë””ì–´ë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]
            
            ğŸ—ºï¸ ROADMAP TO THE MOON (AND BEYOND)
            =====================================
            Q1 2025: [ëª©í‘œë“¤]
            Q2 2025: [ëª©í‘œë“¤]
            Q3 2025: [ëª©í‘œë“¤]
            Q4 2025: [ëª©í‘œë“¤]

            âš ï¸ ëª¨ë“  ë‚´ìš©ì„ ì˜ì–´ë¡œ ì‘ì„±í•˜ê³ , ì§„ì§€í•œ í†¤ìœ¼ë¡œ ì›ƒê¸´ ë‚´ìš©ì„ ì „ë‹¬í•˜ì„¸ìš”. ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ í’ìê¸€ê³¼ ë¹„ìŠ·í•œ ë¬¸ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            Pretend this is an official whitepaper presented to serious investors, but the content is absurd. Never break character.
            """,
            expected_output="í† í¬ë…¸ë¯¹ìŠ¤ì™€ ë¡œë“œë§µì´ í¬í•¨ëœ ì™„ì„±ëœ ë³´ê³ ì„œ",
            agent=self.tokenomics_agent
        )

    def create_summary_task(self):
        return Task(
            description="""
            ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ëª¨ë“  ì •ë³´(í’ìê¸€ + í† í¬ë…¸ë¯¹ìŠ¤ + ë¡œë“œë§µ)ë¥¼ ì›¹ì‚¬ì´íŠ¸ ë´‡ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

            JSON êµ¬ì¡° ìš”êµ¬ì‚¬í•­:
            {
                "name": "ë°ˆì½”ì¸ ì „ì²´ ì´ë¦„",
                "symbol": "ë°ˆì½”ì¸ í‹°ì»¤",
                "description": "ë³¸ë¬¸ ì„¤ëª…",
                "features": ["íŠ¹ì§•1", "íŠ¹ì§•2", "íŠ¹ì§•3"],
                "warning": "íˆ¬ì ê²½ê³ ë¬¸",
                "hashtags": ["í•´ì‹œíƒœê·¸1", "í•´ì‹œíƒœê·¸2", "í•´ì‹œíƒœê·¸3"],
                "tokenomics": {
                    "total_supply": "ì´ ê³µê¸‰ëŸ‰",
                    "distribution": {
                        "team": "íŒ€ í• ë‹¹ ë° ì„¤ëª…",
                        "marketing": "ë§ˆì¼€íŒ… í• ë‹¹ ë° ì„¤ëª…",
                        "liquidity": "ìœ ë™ì„± í• ë‹¹ ë° ì„¤ëª…",
                        "community": "ì»¤ë®¤ë‹ˆí‹° í• ë‹¹ ë° ì„¤ëª…"
                    },
                    "special_features": ["íŠ¹ë³„ ê¸°ëŠ¥1", "íŠ¹ë³„ ê¸°ëŠ¥2"]
                },
                "roadmap": {
                    "Q1_2025": "1ë¶„ê¸° ëª©í‘œ",
                    "Q2_2025": "2ë¶„ê¸° ëª©í‘œ",
                    "Q3_2025": "3ë¶„ê¸° ëª©í‘œ",
                    "Q4_2025": "4ë¶„ê¸° ëª©í‘œ"
                }
            }

            JSON êµ¬ì¡° ì˜ˆì‹œ:

            ì£¼ì˜ì‚¬í•­:
            1. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ì˜ì–´ë¡œ ìœ ì§€
            2. JSON í˜•ì‹ì„ ì •í™•íˆ ë§ì¶°ì£¼ì„¸ìš”
            3. íŠ¹ìˆ˜ ë¬¸ìë‚˜ ì´ëª¨ì§€ëŠ” ìœ ì§€í•˜ë˜ JSONì— ë¬¸ì œê°€ ì—†ë„ë¡ ì²˜ë¦¬
            4. ê° ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì •í™•íˆ ë¶„ë¥˜í•˜ì—¬ ë°°ì¹˜
            """,
            expected_output="ì›¹ì‚¬ì´íŠ¸ ë´‡ ì „ë‹¬ìš© JSON ë°ì´í„°",
            agent=self.summary_agent
        )

    def run_satire_generation(self, keyword: str, why_trending: str):
        print(f"ğŸ¤– '{keyword}' í‚¤ì›Œë“œë¡œ ì „ì²´ ìë™í™” í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print(f"ğŸ“ íŠ¸ë Œë”© ì´ìœ : {why_trending}\n")
        
        # 1. ëª¨ë“  Taskë¥¼ ë¯¸ë¦¬ ì •ì˜í•©ë‹ˆë‹¤. ê° TaskëŠ” ì´ì „ Taskì˜ ê²°ê³¼ë¥¼ contextë¡œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
        search_task = self.create_search_task(keyword, why_trending)
        
        # contextë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
        extraction_task = self.create_extraction_task()
        extraction_task.context = [search_task]
        
        satire_task = self.create_satire_task(keyword)
        satire_task.context = [extraction_task]
        
        tokenomics_task = self.create_tokenomics_task(keyword)
        tokenomics_task.context = [satire_task]
        
        summary_task = self.create_summary_task()
        summary_task.context = [tokenomics_task]

        # 2. Crewë¥¼ ìƒì„±í•˜ê³  ëª¨ë“  Taskë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        crew = Crew(
            agents=[self.search_agent, self.extractor_agent, self.writer_agent, self.tokenomics_agent, self.summary_agent],
            tasks=[search_task, extraction_task, satire_task, tokenomics_task, summary_task],
            process=Process.sequential,
            verbose=True
        )
        
        try:
            # kickoff()ëŠ” ëª¨ë“  ì‘ì—…ì„ ì‹¤í–‰ì‹œí‚¤ëŠ” ì—­í• ë§Œ í•©ë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ë¬¼ì€ ì•„ë˜ì—ì„œ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
            crew.kickoff(inputs={"keyword": keyword, "why_trending": why_trending})
            
            # 3. ì‹¤í–‰ ì™„ë£Œ í›„, í•„ìš”í•œ ê²°ê³¼ë¬¼ì„ ê° Task ê°ì²´ì—ì„œ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
            # .output.rawë¥¼ ì‚¬ìš©í•˜ë©´ ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ ê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            satire_result = satire_task.output.raw
            tokenomics_result = tokenomics_task.output.raw
            summary_json = summary_task.output.raw
            
            # 4. ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ íŒŒì¼ì„ ì €ì¥í•˜ê³  ë°ì´í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            # ìš”êµ¬ì‚¬í•­: 3ë²ˆ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¬¼(í’ìê¸€)ë§Œ ë³„ë„ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
            # ì´ê²ƒì´ ì‹¤ì œ ëŸ°ì¹˜íŒ¨ë“œì— ì˜¬ë¦´ 'ë°ˆì½”ì¸ ì„¤ëª…'ì´ ë©ë‹ˆë‹¤.
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs("./outputs", exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            satire_filename = f"./outputs/launchpad_description_{keyword}_{timestamp}.txt"
            
            with open(satire_filename, "w", encoding="utf-8") as f:
                f.write(satire_result)
            print(f"\nâœ… ëŸ°ì¹˜íŒ¨ë“œìš© ì„¤ëª… íŒŒì¼ ì €ì¥ ì™„ë£Œ: '{satire_filename}'")
            
            # (ì„ íƒ) ë§Œì•½ ì „ì²´ ë¦¬í¬íŠ¸(í’ìê¸€ + í† í¬ë…¸ë¯¹ìŠ¤)ë„ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
            # full_report_filename = f"./outputs/full_report_{keyword}_{timestamp}.txt"
            # with open(full_report_filename, "w", encoding="utf-8") as f:
            #     f.write(f"{satire_result}\n\n{tokenomics_result}")
            # print(f"âœ… ì „ì²´ ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: '{full_report_filename}'")
            
            # 5ë²ˆ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¬¼(JSON)ì€ íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³ ,
            # ì›¹ì‚¬ì´íŠ¸ ë´‡ì—ê²Œ ì „ë‹¬í•˜ê¸° ìœ„í•´ í•¨ìˆ˜ì˜ ìµœì¢… ê²°ê³¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
            print(f"âœ… ì›¹ì‚¬ì´íŠ¸ ë´‡ì—ê²Œ ì „ë‹¬í•  JSON ë°ì´í„° ìƒì„± ì™„ë£Œ.")
            
            return {
                'json_data': summary_json,
                'satire_filename': satire_filename,
                'satire_content': satire_result
            }
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
            # ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ì™„ì„±ëœ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ë°˜í™˜
            try:
                partial_results = self._get_partial_results([search_task, extraction_task, satire_task, tokenomics_task, summary_task])
                return partial_results if partial_results else None
            except:
                return None

    def _get_partial_results(self, tasks):
        """ì—ëŸ¬ ë°œìƒ ì‹œ ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ì™„ì„±ëœ ê²°ê³¼ë¥¼ ë°˜í™˜"""
        results = {}
        
        # ê° taskì˜ outputì´ ìˆëŠ”ì§€ í™•ì¸
        task_names = ['search', 'extraction', 'satire', 'tokenomics', 'summary']
        for i, task in enumerate(tasks):
            try:
                if hasattr(task, 'output') and task.output:
                    results[task_names[i]] = task.output.raw
            except:
                continue
        
        # ìµœì†Œí•œ í’ìê¸€ì´ë¼ë„ ì™„ì„±ë˜ì—ˆë‹¤ë©´ ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
        if 'satire' in results:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            try:
                os.makedirs("./outputs", exist_ok=True)
                satire_filename = f"./outputs/partial_launchpad_description_{timestamp}.txt"
                with open(satire_filename, "w", encoding="utf-8") as f:
                    f.write(results['satire'])
                print(f"âš ï¸ ë¶€ë¶„ ì™„ì„±: í’ìê¸€ë§Œ ì €ì¥ë¨ '{satire_filename}'")
                
                return {
                    'json_data': results.get('summary', None),
                    'satire_filename': satire_filename,
                    'satire_content': results['satire'],
                    'partial': True
                }
            except:
                pass
        
        return None

# íŒ€ ì—°ë™ì„ ìœ„í•œ í•¨ìˆ˜
def generate_satire_for_team(input_data: dict) -> dict:
    """
    íŒ€ì› ì—ì´ì „íŠ¸ì™€ ì—°ë™í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
    
    Args:
        input_data (dict): {
            "keyword": str, 
            "why_trending": str
        }
    
    Returns:
        dict: {
            'json_data': str,           # ì›¹ì‚¬ì´íŠ¸ ë´‡ìš© JSON
            'satire_filename': str,     # ì €ì¥ëœ í’ìê¸€ íŒŒì¼ ê²½ë¡œ
            'satire_content': str,      # í’ìê¸€ ë‚´ìš©
            'partial': bool             # ë¶€ë¶„ ì™„ì„± ì—¬ë¶€ (optional)
        }
    """
    meme_crew = MemeAgentCrew()
    
    keyword = input_data.get("keyword", "")
    why_trending = input_data.get("why_trending", "")
    
    if not keyword:
        return {"error": "í‚¤ì›Œë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        result = meme_crew.run_satire_generation(keyword, why_trending)
        return result if result else {"error": "í’ìê¸€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        return {"error": f"í’ìê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    meme_crew = MemeAgentCrew()
    
    # íŒ€ì› ì—ì´ì „íŠ¸ë¡œë¶€í„° ë°›ì€ ì…ë ¥ ì˜ˆì‹œ
    keyword = "ì†í¥ë¯¼"
    why_trending = "ì†í¥ë¯¼ is a renowned South Korean football player. Recent reports indicate he may be transferring from Tottenham to LA FC."
    
    result = meme_crew.run_satire_generation(keyword, why_trending)
    
    if result and 'error' not in result:
        print("\n" + "="*50)
        print("ğŸ‰ ìƒì„± ì™„ë£Œ!")
        print("="*50)
        
        print("ğŸ“„ ì €ì¥ëœ íŒŒì¼:", result.get('satire_filename'))
        print("ğŸŒ ì›¹ì‚¬ì´íŠ¸ ë´‡ ì „ë‹¬ìš© JSON:")
        print(result.get('json_data'))
        
        if result.get('partial'):
            print("âš ï¸ ì£¼ì˜: ë¶€ë¶„ì ìœ¼ë¡œë§Œ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        if result and 'error' in result:
            print(f"ì—ëŸ¬: {result['error']}")

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜"""
    print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ê°„ë‹¨í•œ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    test_data = {
        "keyword": "ì •ìš°ì„±",
        "why_trending": "Famous Korean actor trending due to rumors"
    }
    
    result = generate_satire_for_team(test_data)
    
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    if 'error' in result:
        print(f"âŒ {result['error']}")
    else:
        print(f"âœ… ì„±ê³µ!")
        print(f"ğŸ“„ íŒŒì¼: {result.get('satire_filename')}")
        print(f"ğŸŒ JSON ë°ì´í„°: {result.get('json_data')[:200]}..." if result.get('json_data') else "JSON ì—†ìŒ")

if __name__ == "__main__":
    # ì‹¤í–‰ ë°©ë²• ì„ íƒ
    print("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì „ì²´ í…ŒìŠ¤íŠ¸ (main)")
    print("2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (quick_test)")
    
    choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "1":
        main()
    elif choice == "2":
        quick_test()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ì „ì²´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        main()