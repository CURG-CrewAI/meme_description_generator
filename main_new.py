# main.py
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import SerperDevTool, ScrapeWebsiteTool
from typing import Dict, Any
import json
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def _get_api_key():
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("Set GEMINI_API_KEY or GOOGLE_API_KEY in your .env")
    return api_key

def _check_serper_key():
    if not os.getenv("SERPER_API_KEY"):
        raise RuntimeError("Set SERPER_API_KEY in your .env (required by SerperDevTool)")

class MemeAgentCrew:
    def __init__(self):
        # ë„êµ¬ ì„¤ì •
        _check_serper_key()
        self.search_tool = SerperDevTool()
        self.scrape_tool = ScrapeWebsiteTool()

        # CrewAIì˜ LLMìœ¼ë¡œ provider+modelì„ ëª…ì‹œ
        api_key = _get_api_key()
        self.gemini_pro = LLM(api_key=api_key, model="gemini/gemini-2.5-pro")
        self.gemini_flash = LLM(api_key=api_key, model="gemini/gemini-2.5-flash")
        self.gemini_flash_lite = LLM(api_key=api_key, model="gemini/gemini-2.5-flash-lite")
     
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ê¸°ì‚¬ URL ìˆ˜ì§‘ ì—ì´ì „íŠ¸
        self.search_agent = Agent(
            role='Korean News Search Expert',
            goal='Collect URLs and titles of the latest Korean news articles for given keywords',
            backstory=(
                """You are a search expert with specialized knowledge of real-time Korean issues and news.
                Your mission is to find the most relevant and reliable Korean news articles for given keywords.
                You prioritize searching articles from major news outlets such as Naver News, Daum News, 
                Yonhap News, Chosun Ilbo, and JoongAng Ilbo.
                When searching, you utilize site-specific searches like site:naver.com or site:daum.net."""
            ),
            tools=[self.search_tool],
            verbose=True,
            llm=self.gemini_flash_lite
        )
       
        # ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ëŠ” ì—ì´ì „íŠ¸
        self.extractor_agent = Agent(
            role='News Content Extraction Expert',
            goal='Extract and summarize core content from article URLs',
            backstory=(
                """You are an expert at extracting key information from web pages.
                You accurately extract article titles, body content, and key information to provide 
                necessary data for subsequent AI Agents' article summarization, translation, and satirical writing tasks.
                You exclude advertisements and unnecessary content, focusing only on pure article content.
                You specialize in identifying important facts and background information from Korean-language articles."""
            ),
            tools=[self.scrape_tool],
            verbose=True,
            llm=self.gemini_flash_lite
        )
    
        # ìš”ì•½í•œ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì·¨í•©í•˜ì—¬ ìš”ì•½í•˜ê³  ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì—ì´ì „íŠ¸
        self.translator_agent = Agent(
            role='Article Summarization and English Translation Expert',
            goal='Summarize Korean articles to appropriate length and translate them into English',
            backstory=(
                """You are an expert at compiling, summarizing, and translating extracted Korean news 
                in a way that global readers can easily understand.
                You translate complex Korean issues clearly with context and background 
                so that foreigners can easily comprehend them."""
            ),
            verbose=True,                             
            llm=self.gemini_flash
        )

        # ì›¹ì‚¬ì´íŠ¸ìš© ì„¤ëª… ìƒì„± ì—ì´ì „íŠ¸
        self.description_agent = Agent(
            role='Website Description Generator',
            goal='Create concise 3-4 sentence descriptions for website tone setting',
            backstory=("""
            You are an expert at creating brief, impactful descriptions that set the overall tone for websites.
            You specialize in distilling complex Korean issues into clear, neutral explanations 
            that foreign readers can quickly understand and that determine the website's atmosphere.
            """),
            verbose=True,
            llm=self.gemini_flash
        )

        # ì´ìŠˆì— ëŒ€í•œ í’ìê¸€ì„ ì‘ì„±í•˜ëŠ” ì—ì´ì „íŠ¸
        self.writer_agent = Agent(
            role='Memecoin Satirical Content Writing Expert',
            goal='Create funny and creative English memecoin satirical content based on collected news information',
            backstory="""
            You are a creative writer well-versed in Korean internet culture and memes, 
            with extensive knowledge of global cryptocurrency and memecoin trends.
            You specialize in writing English satirical content that humorously presents Korean current affairs 
            while maintaining appropriate boundaries and fitting the memecoin concept.

            Writing Style:
            - Explain Korean issues in English that global audiences can understand
            - Creative naming and concepts that leverage memecoin characteristics
            - Appropriate use of emojis and hashtags
            - Healthy humor that is not excessive

            âš ï¸ Important: All content must be written in English.
            """,
            verbose=True,
            llm=self.gemini_pro
        )

        # í† í¬ë…¸ë¯¹ìŠ¤ì™€ ë¡œë“œë§µì„ ì‘ì„±í•˜ëŠ” ì—ì´ì „íŠ¸
        self.tokenomics_agent = Agent(
            role='Memecoin Tokenomics & Roadmap Designer',
            goal='Generate absurd and funny tokenomics and roadmaps based on satirical content',
            backstory="""
            You are an expert at creating memecoin projects that are so absurd they make people laugh out loud.
            You create plausible-sounding tokenomics and impossible roadmaps that maximize satire and humor,
            just like actual crypto projects.

            Writing Style:
            - Use professional terminology like actual whitepapers but with nonsensical content
            - Utilize fake data with pie charts, percentages, and numbers
            - Quarterly roadmaps like Q1, Q2 with impossible goals
            - Deliver funny content with a serious tone

            âš ï¸ Important: All content must be written in English.
            """,
            verbose=True,
            llm=self.gemini_pro  
        )

        # ì›¹ì‚¬ì´íŠ¸ ë´‡ ì „ë‹¬ìš© JSON ë³€í™˜ ì—ì´ì „íŠ¸
        self.summary_agent = Agent(
            role='Website Bot Integration JSON Conversion Expert',
            goal='Convert satirical content and tokenomics into JSON format usable by website bots',
            backstory="""
            You are an expert at converting various data into structured JSON formats.
            Your mission is to organize all memecoin project information into forms that are easy to use on websites.
            You clearly separate each section and structure them so they can be easily parsed by websites.
            """,
            verbose=True,
            llm=self.gemini_flash
        )

    def create_search_task(self, keyword: str, why_trending: str):
        context_term = (why_trending or "").split(".")[0]
        return Task(
            description=f"""
            Based on the given keyword '{keyword}' and trending reason '{why_trending}', you need to find the most accurate and relevant latest Korean news articles.

            Instead of simply searching by keywords alone, use the following search strategies to improve search quality:

            1. **Targeted News Portal Search:** Directly target high-credibility major portals like `"{keyword}" site:news.naver.com` or `"{keyword}" site:v.daum.net`.
            2. **Context-Driven Search:** Extract key terms from the trending reason and combine them with the search term. Example: `"{keyword}" {context_term}`
            3. **Latest News Search:** Combine keywords like `"{keyword}" ìµœì‹  ë‰´ìŠ¤` or `"{keyword}" ê³µì‹ì…ì¥` to find the most recent information.

            Using these strategies comprehensively, collect 3-5 reliable latest articles with titles, URLs, and brief summaries.

            Results must be organized in the following JSON format:
            {{
            "keyword": "{keyword}",
            "articles": [
                {{
                    "title": "Article Title",
                    "url": "Article URL", 
                    "snippet": "Article Summary",
                    "source": "Media Outlet Name"
                }}
            ]
        }}
        """,
        expected_output="JSON format string containing information about 5-7 reliable latest articles",
        agent=self.search_agent
    )
    
    def create_extraction_task(self):
        return Task(
            description="""
            Extract body content from the article URLs collected in the previous step.
            
            Extraction Requirements:
            1. Access each URL and extract article body content
            2. Focus on extracting titles and key content from the first 2-3 paragraphs
            3. Exclude advertisements, related articles, comments, etc.
            4. Organize only key facts and contextual information
            5. Clearly identify issue background and current situation
            6. Skip inaccessible or failed extraction URLs and continue processing
            7. Write results using only successfully extracted articles
            8. Consider task complete if at least 1 article is successfully extracted
            9. If text contains repeated sentences more than 5 times, skip that article
            10. If Unicode decoding errors occur, skip that specific article and continue

            Error Handling:
            - Exclude only the specific article for URL access failures, scraping blocks, etc.
            - Log failed articles but do not stop the entire operation
            - Compose extracted_content array only with extractable articles
            
            Organize results in the following format:
            {{
                "extracted_content": [
                    {{
                        "title": "Article Title",
                        "url": "Article URL",
                        "content": "Extracted Key Body Content",
                        "key_points": ["Key Point 1", "Key Point 2", "Key Point 3"],
                        "background": "Issue Background",
                        "source": "Media Outlet Name"
                    }}
                ]
            }}
            """,
            expected_output="Extracted article body content in JSON format",
            agent=self.extractor_agent
        )
    
    def create_translation_task(self):
        return Task(
            description="""
            Compile, summarize, and translate the extracted JSON format article content from the previous step into English.

            Processing Steps:
            1. Comprehensively analyze all article content in the extracted_content array
            2. Identify common themes and key content from multiple articles
            3. Extract 2-3 key keywords suitable for image generation (key person names, places, core concepts, key objects, etc.)
            - Examples: "Son Heung-min, LAFC Stadium, Soccer Ball" or "Lee Jae-myung, 250,000 won"
            - Select keywords focusing on specific, searchable nouns
            - Prioritize visually representable elements over abstract concepts
            4. Write content within 200-300 words total
            5. Include actual URLs in the Sources section
            6. Include Korean cultural context and background explanations for foreign understanding
            7. Translate everything into English considering foreign readers

            Output Format:
            # Korean Issue Summary: [Issue Title]

            **Key Visual Keywords:** ["Keyword1","Keyword2","Keyword3"]

            **Background:** 
            [Korean cultural/social context explanation]

            **What Happened:** 
            [Current situation and major events]

            **Key Points:**
            - [Key Point 1]
            - [Key Point 2] 
            - [Key Point 3]

            **Why It Matters:**
            [Why this issue is important and noteworthy]

            This summary serves as material to help foreigners interested in memecoins understand the background of Korean issues.

            **Sources:**
            [Media Outlet] - [Article Title] - [URL]

            Write media outlet names, article titles, and source URLs in English.
            Must include all sources used for compilation.
            Provide 2-3 or more different media outlet sources when possible.
            List as many as the actual number of referenced articles.

            Reference the following examples:
            - Yonhap News Agency - "Lawmaker Lee Under Investigation for Stock Trading" - https://...
            - JTBC News - "45 People Questioned in Nominee Trading Case" - https://...
            - KBS News - "Police Analyze Financial Records in Political Scandal" - https://...

            Note: Use actual URLs, not [URL Placeholder].
            """,
            expected_output="Korean issue comprehensive summary translated into English",
            agent=self.translator_agent
        )

    def create_description_task(self):
        return Task(
            description="""
            Based on the Korean issue summary from the previous step, create a concise 3-4 sentence description that sets the overall tone for the website.

            Requirements:
            - Length: 3-4 sentences, 80-120 words
            - Purpose: Core summary for determining website atmosphere
            - Include: Who, what, why it's problematic (briefly)
            - Exclude: Detailed background explanations, Key Points listing
            - Tone: Information-focused neutral tone
            - Target: Foreign readers unfamiliar with Korean issues

            Writing Guide:
            1. First sentence: Simply explain who did what
            2. Second sentence: Core issues or problems
            3. Final sentence: Why this issue is important

            Example: "South Korean lawmaker Lee Chun-seok is under investigation for alleged stock trading using nominee accounts worth 1 billion won. The amount significantly exceeds his declared assets, raising questions about the source of funds. This case highlights ongoing concerns about financial transparency in Korean politics."

            Reference the example but do not copy it directly.
            """,
            expected_output="3-4 sentence concise description for website tone setting",
            agent=self.description_agent
    )

    def create_satire_task(self, keyword: str):
        return Task(
            description=f"""
            Write English memecoin satirical content based on the collected information about keyword '{keyword}'.
            
            Satirical Content Requirements:
            1. Title: Creative memecoin name and ticker ex) Sonnywood, $SONNY
            2. Body: Funny English explanation of the issue (100-250 words)
            3. Features: 1-4 humorous features of the memecoin (in English)
            4. Hashtags: 5-7 related English hashtags

            Tone and Style:
            - Humorous but dignified
            - English expressions that global audiences can understand
            - Use emojis appropriately
            - Mix irony and satire through exaggeration, metaphors, wordplay, etc.
            - Explain Korean cultural context well in English
            - Make unfamiliar Korean issues understandable
            âš ï¸ Important: Write all content in English.
            
            Writing Format:
            ğŸš€ [COIN_NAME] 
            
            "[English Catchphrase]"
            
            [Korean issue explained in English with humor]
            
            âœ¨ Features:
            - Feature 1 in English
            - Feature 2 in English
            - Feature 3 in English
            
            #hashtag1 #hashtag2 #hashtag3 #hashtag4 #hashtag5

            Writing Guide (Few Shot):
            Below is an example of successful satirical writing on the theme of 'actor's private life cannot be confirmed.' 
            Learn from this example's creative approach and apply it to your results.

            Topic: Actor Jung Woo-sung's official statement that his 'private life cannot be confirmed'
            Excellent Features writing example:
            âœ¨ Features:
            - Non-Denial-Denial Protocol: Transactions are never officially confirmed, they just appear on the blockchain. We respect their privacy.
            - Plot Twist Burn Mechanism: A small percentage of the total supply is automatically burned every time a shocking new personal detail about a major public figure is "unable to be confirmed."
            - Stealth Wedding Rewards: Holders are airdropped bonus tokens when a long-term bachelor/bachelorette finallyâ€”and quietlyâ€”gets married without a press release.

            Key Learning Points: Do not copy the above example directly.
            Instead, your mission is to maximize humor by cleverly packaging the core satirical concept with **plausible blockchain-related technical terms like 'Protocol', 'Mechanism', 'Rewards', 'Tokenomics', 'Governance'**. Creatively choose terms that best fit your topic.
            For example, when satirizing politicians, Governance Model or Voting System might be more suitable, while food-related issues could be funnier with Supply Chain Tokenomics.
            """,
            expected_output="Complete English memecoin satirical content",
            agent=self.writer_agent
        )

    def create_tokenomics_task(self, keyword: str):
        return Task(
            description=f"""
            Write tokenomics and roadmap based on the '{keyword}' memecoin satirical content generated in the previous step (context).

            Your most important mission is **maintaining content consistency**.
            You must **bring the `âœ¨ Features` items presented in the satirical content introduction to your `TOKENOMICS` `Special Features` section and explain them in detail.** Never ignore these ideas and create new mechanisms.

            ğŸ’¡ **Workflow Guide:**
            1. Carefully read the `âœ¨ Features` section from the satirical content received as context.
            2. Use the names of those features exactly as section titles for your `TOKENOMICS` `Special Features` section.
            3. Creatively and entertainingly explain how each feature works specifically from a tokenomics perspective (e.g., staking methods, burning methods, reward methods, etc.).
            4. If you want to add new mechanisms not in the satirical content (e.g., general burning), it's acceptable to add them **after** explaining all existing features.

            ğŸ“Š TOKENOMICS Requirements:
            1. Distribution:
            - Team: 0-1% (with funny reasons, team allocation should preferably be minimal)
            - Marketing: X% (absurd marketing plans)
            - Liquidity: X% 
            - Community: X% (ridiculous community benefits)
            2. Special Features:
            **(Required) Detailed explanation of ideas brought from the satirical content's `âœ¨ Features`**

            ğŸ—ºï¸ ROADMAP Requirements:
            Q1 2025: [Unbelievable but somewhat realistic goals]
            Q2 2025: [Nearly impossible absurd goals]
            Q3 2025: [Completely impossible goals that violate physical laws]
            Q4 2025: [Universe conquest/time travel level goals]

            Format:
            ğŸ“Š TOKENOMICS
            ================
            Distribution:
            - Team: 0-1% - [Funny explanation]
            - Marketing: X% - [Absurd plans]
            - Liquidity: X% - [Exaggerated explanation]
            - Community: X% - [Ridiculous benefits]

            Special Features:
            - [Detailed explanation of ideas brought from satirical content's `âœ¨ Features`]
            - [Detailed explanation of ideas brought from satirical content's `âœ¨ Features`]
            - [Detailed explanation of ideas brought from satirical content's `âœ¨ Features`]

            ğŸ—ºï¸ ROADMAP TO THE MOON (AND BEYOND)
            =====================================
            Q1 2025: [Goals]
            Q2 2025: [Goals]
            Q3 2025: [Goals]
            Q4 2025: [Goals]

            âš ï¸ Write all content in English and deliver funny content with a serious tone. Write in a similar style to the satirical content generated in the previous step.
            Pretend this is an official whitepaper presented to serious investors, but the content is absurd. Never break character.
            """,
            expected_output="Complete report including tokenomics and roadmap",
            agent=self.tokenomics_agent
        )

    def create_summary_task(self):
        return Task(
            description="""
            Convert all information generated in previous steps (article summaries, satirical content, etc.) into JSON format usable by website bots.

            JSON Structure Requirements:
            {
                "name": "Full memecoin name",
                "symbol": "Memecoin ticker",
                "description": "Use the result generated by description_task as is",
                "korean_issue_summary": {
                    "title": "Issue title",
                    "background": "Korean cultural/social context explanation",
                    "what_happened": "Current situation and major events",
                    "key_points": ["Key Point 1", "Key Point 2", "Key Point 3"],
                    "why_it_matters": "Why this issue is important and noteworthy"
                },
                "sources": [
                    {
                        "outlet": "Media outlet name",
                        "title": "Article title",
                        "url": "Article URL"
                    }
                ],
                "hashtags": ["Hashtag1", "Hashtag2", "Hashtag3"],
            }

            JSON Structure Example:

            Guidelines:
            1. Keep all text in English
            2. Ensure accurate JSON formatting
            3. Maintain special characters and emojis but ensure they don't break JSON structure
            4. Accurately classify and place content in each section
            5. For the "description" field, use the 3-4 sentence summary from the description_task result as is
            """,
            expected_output="JSON data for website bot delivery",
            agent=self.summary_agent
        )

    def run_satire_generation(self, keyword: str, why_trending: str):
        print(f"ğŸ¤– '{keyword}' í‚¤ì›Œë“œë¡œ ì „ì²´ ìë™í™” í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print(f"ğŸ“ íŠ¸ë Œë”© ì´ìœ : {why_trending}\n")
        
        # 1. ëª¨ë“  Taskë¥¼ ë¯¸ë¦¬ ì •ì˜í•©ë‹ˆë‹¤. ê° TaskëŠ” ì´ì „ Taskì˜ ê²°ê³¼ë¥¼ contextë¡œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
        search_task = self.create_search_task(keyword, why_trending)
        
        # contextë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
        extraction_task = self.create_extraction_task()
        extraction_task.context = [search_task]
        
        translation_task = self.create_translation_task()
        translation_task.context = [extraction_task]

        description_task = self.create_description_task()
        description_task.context = [translation_task]

        satire_task = self.create_satire_task(keyword)
        satire_task.context = [extraction_task]
        
        tokenomics_task = self.create_tokenomics_task(keyword)
        tokenomics_task.context = [satire_task]
        
        summary_task = self.create_summary_task()
        summary_task.context = [translation_task, description_task, tokenomics_task]

        # 2. Crewë¥¼ ìƒì„±í•˜ê³  ëª¨ë“  Taskë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        crew = Crew(
            agents=[self.search_agent, self.extractor_agent, self.translator_agent, self.description_agent, self.writer_agent, self.tokenomics_agent, self.summary_agent],
            tasks=[search_task, extraction_task, translation_task, description_task, satire_task, tokenomics_task, summary_task],
            process=Process.sequential,
            verbose=True
        )
        
        try:
            # kickoff()ëŠ” ëª¨ë“  ì‘ì—…ì„ ì‹¤í–‰ì‹œí‚¤ëŠ” ì—­í• ë§Œ í•©ë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ë¬¼ì€ ì•„ë˜ì—ì„œ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
            crew.kickoff(inputs={"keyword": keyword, "why_trending": why_trending})
            
            # 3. ì‹¤í–‰ ì™„ë£Œ í›„, í•„ìš”í•œ ê²°ê³¼ë¬¼ì„ ê° Task ê°ì²´ì—ì„œ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
            # .output.rawë¥¼ ì‚¬ìš©í•˜ë©´ ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ ê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            translation_result = translation_task.output.raw
            description_result = description_task.output.raw
            satire_result = satire_task.output.raw
            tokenomics_result = tokenomics_task.output.raw
            summary_json = summary_task.output.raw
            
            # 4. ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ íŒŒì¼ì„ ì €ì¥í•˜ê³  ë°ì´í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            # ìš”êµ¬ì‚¬í•­: 3ë²ˆ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¬¼(í’ìê¸€)ë§Œ ë³„ë„ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
            # ì´ê²ƒì´ ì‹¤ì œ ëŸ°ì¹˜íŒ¨ë“œì— ì˜¬ë¦´ 'ë°ˆì½”ì¸ ì„¤ëª…'ì´ ë©ë‹ˆë‹¤.
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs("./outputs", exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            
            translation_filename = f"./outputs/korean_issue_summary_{keyword}_{timestamp}.txt"
            with open(translation_filename, "w", encoding="utf-8") as f:
                f.write(translation_result)
            print(f"âœ… í•œêµ­ ì´ìŠˆ ìš”ì•½ë³¸ ì €ì¥ ì™„ë£Œ: '{translation_filename}'")

            description_filename = f"./outputs/website_description_{keyword}_{timestamp}.txt"
            with open(description_filename, "w", encoding="utf-8") as f:
                f.write(description_result)
            print(f"âœ… ì›¹ì‚¬ì´íŠ¸ ì„¤ëª… ì €ì¥ ì™„ë£Œ: '{description_filename}'")

            satire_filename = f"./outputs/launchpad_description_{keyword}_{timestamp}.txt"
            with open(satire_filename, "w", encoding="utf-8") as f:
                f.write(satire_result)
            print(f"\nâœ… ëŸ°ì¹˜íŒ¨ë“œìš© ì„¤ëª… íŒŒì¼ ì €ì¥ ì™„ë£Œ: '{satire_filename}'")
        
            # (ì„ íƒ) ë§Œì•½ ì „ì²´ ë¦¬í¬íŠ¸(í’ìê¸€ + í† í¬ë…¸ë¯¹ìŠ¤)ë„ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
            # full_report_filename = f"./outputs/full_report_{keyword}_{timestamp}.txt"
            # with open(full_report_filename, "w", encoding="utf-8") as f:
            #     f.write(f"{satire_result}\n\n{tokenomics_result}")
            # print(f"âœ… ì „ì²´ ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: '{full_report_filename}'")
            
            # 5ë²ˆ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¬¼(JSON)ì€ íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³ ,
            # ì›¹ì‚¬ì´íŠ¸ ë´‡ì—ê²Œ ì „ë‹¬í•˜ê¸° ìœ„í•´ í•¨ìˆ˜ì˜ ìµœì¢… ê²°ê³¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
            print(f"âœ… ì›¹ì‚¬ì´íŠ¸ ë´‡ì—ê²Œ ì „ë‹¬í•  JSON ë°ì´í„° ìƒì„± ì™„ë£Œ.")
            
            return {
                'json_data': summary_json,
                'satire_filename': satire_filename,
                'satire_content': satire_result
            }
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
            # ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ì™„ì„±ëœ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ë°˜í™˜
            try:
                partial_results = self._get_partial_results([search_task, extraction_task, translation_task, description_task, satire_task, tokenomics_task, summary_task])
                return partial_results if partial_results else None
            except:
                return None

    def _get_partial_results(self, tasks):
        """ì—ëŸ¬ ë°œìƒ ì‹œ ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ì™„ì„±ëœ ê²°ê³¼ë¥¼ ë°˜í™˜"""
        results = {}

        
        # ê° taskì˜ outputì´ ìˆëŠ”ì§€ í™•ì¸
        task_names = ['search', 'extraction', 'translation', 'description', 'satire', 'tokenomics', 'summary']
        for i, task in enumerate(tasks):
            try:
                if hasattr(task, 'output') and task.output:
                    results[task_names[i]] = task.output.raw
            except:
                continue
        
        # ìµœì†Œí•œ í’ìê¸€ì´ë¼ë„ ì™„ì„±ë˜ì—ˆë‹¤ë©´ ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
        if 'satire' in results:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            try:
                os.makedirs("./outputs", exist_ok=True)
                satire_filename = f"./outputs/partial_launchpad_description_{timestamp}.txt"
                with open(satire_filename, "w", encoding="utf-8") as f:
                    f.write(results['satire'])
                print(f"âš ï¸ ë¶€ë¶„ ì™„ì„±: í’ìê¸€ë§Œ ì €ì¥ë¨ '{satire_filename}'")
                
                return {
                    'json_data': results.get('summary', None),
                    'satire_filename': satire_filename,
                    'satire_content': results['satire'],
                    'partial': True
                }
            except:
                pass
        
        return None

# íŒ€ ì—°ë™ì„ ìœ„í•œ í•¨ìˆ˜
def generate_satire_for_team(input_data: dict) -> dict:
    """
    íŒ€ì› ì—ì´ì „íŠ¸ì™€ ì—°ë™í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
    
    Args:
        input_data (dict): {
            "keyword": str, 
            "why_trending": str
        }
    
    Returns:
        dict: {
            'json_data': str,           # ì›¹ì‚¬ì´íŠ¸ ë´‡ìš© JSON
            'satire_filename': str,     # ì €ì¥ëœ í’ìê¸€ íŒŒì¼ ê²½ë¡œ
            'satire_content': str,      # í’ìê¸€ ë‚´ìš©
            'partial': bool             # ë¶€ë¶„ ì™„ì„± ì—¬ë¶€ (optional)
        }
    """
    meme_crew = MemeAgentCrew()
    
    keyword = input_data.get("keyword", "")
    why_trending = input_data.get("why_trending", "")
    
    if not keyword:
        return {"error": "í‚¤ì›Œë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        result = meme_crew.run_satire_generation(keyword, why_trending)
        return result if result else {"error": "í’ìê¸€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        return {"error": f"í’ìê¸€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    meme_crew = MemeAgentCrew()
    
    # íŒ€ì› ì—ì´ì „íŠ¸ë¡œë¶€í„° ë°›ì€ ì…ë ¥ ì˜ˆì‹œ
    keyword = "ì‹œë“œë‹ˆ ìŠ¤ìœ„ë‹ˆ"
    why_trending = "Sydney Sweeney is an American actress. She's trending due to controversy surrounding an advertisement for American Eagle jeans."
    
    result = meme_crew.run_satire_generation(keyword, why_trending)
    
    if result and 'error' not in result:
        print("\n" + "="*50)
        print("ğŸ‰ ìƒì„± ì™„ë£Œ!")
        print("="*50)
        
        print("ğŸ“„ ì €ì¥ëœ íŒŒì¼:", result.get('satire_filename'))
        print("ğŸŒ ì›¹ì‚¬ì´íŠ¸ ë´‡ ì „ë‹¬ìš© JSON:")
        print(result.get('json_data'))
        
        if result.get('partial'):
            print("âš ï¸ ì£¼ì˜: ë¶€ë¶„ì ìœ¼ë¡œë§Œ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        if result and 'error' in result:
            print(f"ì—ëŸ¬: {result['error']}")

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜"""
    print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ê°„ë‹¨í•œ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    test_data = {
        "keyword": "ì •ìš°ì„±",
        "why_trending": "Famous Korean actor trending due to rumors"
    }
    
    result = generate_satire_for_team(test_data)
    
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    if 'error' in result:
        print(f"âŒ {result['error']}")
    else:
        print(f"âœ… ì„±ê³µ!")
        print(f"ğŸ“„ íŒŒì¼: {result.get('satire_filename')}")
        print(f"ğŸŒ JSON ë°ì´í„°: {result.get('json_data')[:200]}..." if result.get('json_data') else "JSON ì—†ìŒ")

if __name__ == "__main__":
    # ì‹¤í–‰ ë°©ë²• ì„ íƒ
    print("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì „ì²´ í…ŒìŠ¤íŠ¸ (main)")
    print("2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (quick_test)")
    
    choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "1":
        main()
    elif choice == "2":
        quick_test()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ì „ì²´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        main()